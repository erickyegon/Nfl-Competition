{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üîç NFL Data Exploration - Deep Dive\n",
    "\n",
    "**Comprehensive Data Analysis and Visualization**\n",
    "\n",
    "This notebook provides an in-depth exploration of the NFL player tracking data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [Data Loading](#loading)\n",
    "3. [Data Dictionary](#dictionary)\n",
    "4. [Statistical Analysis](#stats)\n",
    "5. [Distribution Analysis](#distributions)\n",
    "6. [Correlation Analysis](#correlations)\n",
    "7. [Player Position Analysis](#positions)\n",
    "8. [Game/Play Analysis](#games)\n",
    "9. [Field Position Heatmaps](#heatmaps)\n",
    "10. [Key Insights](#insights)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "OUTPUT_DIR = Path('../outputs/data_exploration')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading",
   "metadata": {},
   "source": [
    "## 2. Data Loading üìÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": "# Load sample data\ntrain_dir = DATA_DIR / 'raw' / 'train'\ninput_files = sorted(train_dir.glob('input_*.csv'))[:2]\noutput_files = sorted(train_dir.glob('output_*.csv'))[:2]\n\nprint(\"üìÇ Loading data files...\")\ninput_df = pd.concat([pd.read_csv(f) for f in input_files], ignore_index=True)\noutput_df = pd.concat([pd.read_csv(f) for f in output_files], ignore_index=True)\n\n# Sample for faster exploration\nSAMPLE_SIZE = 50000\nif len(input_df) > SAMPLE_SIZE:\n    input_df = input_df.sample(n=SAMPLE_SIZE, random_state=42)\n    # Filter output to match sampled input using proper keys\n    sampled_keys = input_df[['game_id', 'play_id', 'nfl_id', 'frame_id']]\n    output_df = output_df.merge(sampled_keys, on=['game_id', 'play_id', 'nfl_id', 'frame_id'])\n\nprint(f\"‚úÖ Data loaded\")\nprint(f\"   Input: {input_df.shape}\")\nprint(f\"   Output: {output_df.shape}\")"
  },
  {
   "cell_type": "markdown",
   "id": "dictionary",
   "metadata": {},
   "source": [
    "## 3. Data Dictionary üìñ\n",
    "\n",
    "Understanding the columns and their meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dict",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Tracking Data': {\n",
    "        'x': 'Player X position (yards, 0-120)',\n",
    "        'y': 'Player Y position (yards, 0-53.3)',\n",
    "        's': 'Speed (yards/second)',\n",
    "        'a': 'Acceleration (yards/second¬≤)',\n",
    "        'dir': 'Direction of motion (degrees, 0-360)',\n",
    "        'o': 'Orientation/body angle (degrees, 0-360)'\n",
    "    },\n",
    "    'Player Info': {\n",
    "        'nfl_id': 'Unique player identifier',\n",
    "        'player_name': 'Player name',\n",
    "        'player_position': 'Player position (QB, WR, CB, etc.)',\n",
    "        'player_weight': 'Player weight (pounds)',\n",
    "        'player_height': 'Player height (feet-inches)',\n",
    "        'player_role': 'Role in play (Passer, Targeted Receiver, etc.)'\n",
    "    },\n",
    "    'Game Context': {\n",
    "        'game_id': 'Unique game identifier',\n",
    "        'play_id': 'Unique play identifier within game',\n",
    "        'frame_id': 'Frame number in play sequence',\n",
    "        'ball_land_x': 'X coordinate where ball lands',\n",
    "        'ball_land_y': 'Y coordinate where ball lands'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìñ DATA DICTIONARY\")\n",
    "print(\"=\" * 70)\n",
    "for category, fields in data_dict.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for field, desc in fields.items():\n",
    "        if field in input_df.columns:\n",
    "            print(f\"  ‚úì {field:20s} - {desc}\")\n",
    "\n",
    "print(f\"\\n\\nüìã Column Info:\")\n",
    "print(f\"   Total columns: {len(input_df.columns)}\")\n",
    "print(f\"   Numeric columns: {len(input_df.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"   Categorical columns: {len(input_df.select_dtypes(include=['object']).columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats",
   "metadata": {},
   "source": [
    "## 4. Statistical Analysis üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Key numeric columns\n",
    "key_cols = ['x', 'y', 's', 'a', 'dir', 'o', 'player_weight']\n",
    "available_cols = [c for c in key_cols if c in input_df.columns]\n",
    "\n",
    "stats_df = input_df[available_cols].describe()\n",
    "display(stats_df)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n‚ùì Missing Values:\")\n",
    "missing = input_df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "if len(missing) > 0:\n",
    "    for col, count in missing.items():\n",
    "        pct = 100 * count / len(input_df)\n",
    "        print(f\"   {col:20s}: {count:>8,} ({pct:>5.1f}%)\")\n",
    "else:\n",
    "    print(\"   ‚úì No missing values\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nüìã Data Types:\")\n",
    "print(input_df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributions",
   "metadata": {},
   "source": [
    "## 5. Distribution Analysis üìà\n",
    "\n",
    "Analyzing distributions of key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dist_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "plot_cols = ['x', 'y', 's', 'a', 'dir', 'o', 'player_weight', 'ball_land_x', 'ball_land_y']\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(plot_cols)))\n",
    "\n",
    "for idx, col in enumerate(plot_cols):\n",
    "    if col in input_df.columns:\n",
    "        data = input_df[col].dropna()\n",
    "        axes[idx].hist(data, bins=50, edgecolor='black', alpha=0.7, color=colors[idx])\n",
    "        axes[idx].set_title(f'{col} Distribution', fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        mean_val = data.mean()\n",
    "        median_val = data.median()\n",
    "        axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "        axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "        axes[idx].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Distribution plots saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speed_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed analysis by player role\n",
    "if 's' in input_df.columns and 'player_role' in input_df.columns:\n",
    "    print(\"üèÉ SPEED ANALYSIS BY PLAYER ROLE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    speed_by_role = input_df.groupby('player_role')['s'].agg(['mean', 'median', 'std', 'count'])\n",
    "    speed_by_role = speed_by_role.sort_values('mean', ascending=False)\n",
    "    display(speed_by_role)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    input_df.boxplot(column='s', by='player_role', ax=ax, rot=45)\n",
    "    plt.suptitle('')\n",
    "    ax.set_title('Speed Distribution by Player Role', fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Player Role', fontsize=12)\n",
    "    ax.set_ylabel('Speed (yards/sec)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'speed_by_role.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlations",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis üîó\n",
    "\n",
    "Exploring relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = ['x', 'y', 's', 'a', 'dir', 'o', 'player_weight']\n",
    "available_numeric = [c for c in numeric_cols if c in input_df.columns]\n",
    "\n",
    "corr_matrix = input_df[available_numeric].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Top correlations\n",
    "print(\"\\nüîó Top Positive Correlations:\")\n",
    "corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
    "corr_pairs = corr_pairs[corr_pairs < 1.0]  # Remove self-correlations\n",
    "for (var1, var2), corr in corr_pairs.head(5).items():\n",
    "    print(f\"   {var1} <-> {var2}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nüîó Top Negative Correlations:\")\n",
    "for (var1, var2), corr in corr_pairs.tail(5).items():\n",
    "    print(f\"   {var1} <-> {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positions",
   "metadata": {},
   "source": [
    "## 7. Player Position Analysis üë•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pos_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_position' in input_df.columns:\n",
    "    print(\"üë• PLAYER POSITION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Position counts\n",
    "    pos_counts = input_df['player_position'].value_counts()\n",
    "    print(\"\\nüìä Position Distribution:\")\n",
    "    print(pos_counts)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Bar plot\n",
    "    pos_counts.head(15).plot(kind='barh', ax=axes[0], color='skyblue', edgecolor='black')\n",
    "    axes[0].set_title('Top 15 Player Positions', fontweight='bold', fontsize=14)\n",
    "    axes[0].set_xlabel('Count', fontsize=12)\n",
    "    axes[0].set_ylabel('Position', fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Pie chart (top 10)\n",
    "    pos_counts.head(10).plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "    axes[1].set_title('Top 10 Position Distribution', fontweight='bold', fontsize=14)\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'position_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Physical attributes by position\n",
    "    if 'player_weight' in input_df.columns:\n",
    "        print(\"\\n‚öñÔ∏è Average Weight by Position (Top 10):\")\n",
    "        weight_by_pos = input_df.groupby('player_position')['player_weight'].mean().sort_values(ascending=False)\n",
    "        print(weight_by_pos.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "games",
   "metadata": {},
   "source": [
    "## 8. Game/Play Analysis üèà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "game_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèà GAME/PLAY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'game_id' in input_df.columns:\n",
    "    print(f\"\\nüìä Number of games: {input_df['game_id'].nunique()}\")\n",
    "    \n",
    "if 'play_id' in input_df.columns:\n",
    "    print(f\"üìä Number of plays: {input_df['play_id'].nunique()}\")\n",
    "    \n",
    "    # Plays per game\n",
    "    if 'game_id' in input_df.columns:\n",
    "        plays_per_game = input_df.groupby('game_id')['play_id'].nunique()\n",
    "        print(f\"\\nüìà Plays per game:\")\n",
    "        print(f\"   Mean: {plays_per_game.mean():.1f}\")\n",
    "        print(f\"   Median: {plays_per_game.median():.1f}\")\n",
    "        print(f\"   Min: {plays_per_game.min()}\")\n",
    "        print(f\"   Max: {plays_per_game.max()}\")\n",
    "\n",
    "if 'frame_id' in input_df.columns:\n",
    "    print(f\"\\nüìä Number of frames: {input_df['frame_id'].nunique()}\")\n",
    "    \n",
    "    # Frames per play\n",
    "    if 'play_id' in input_df.columns:\n",
    "        frames_per_play = input_df.groupby('play_id')['frame_id'].nunique()\n",
    "        print(f\"\\nüìà Frames per play:\")\n",
    "        print(f\"   Mean: {frames_per_play.mean():.1f}\")\n",
    "        print(f\"   Median: {frames_per_play.median():.1f}\")\n",
    "        print(f\"   Min: {frames_per_play.min()}\")\n",
    "        print(f\"   Max: {frames_per_play.max()}\")\n",
    "\n",
    "# Players per play\n",
    "if all(col in input_df.columns for col in ['play_id', 'nfl_id']):\n",
    "    players_per_play = input_df.groupby('play_id')['nfl_id'].nunique()\n",
    "    print(f\"\\nüë• Players per play:\")\n",
    "    print(f\"   Mean: {players_per_play.mean():.1f}\")\n",
    "    print(f\"   Median: {players_per_play.median():.1f}\")\n",
    "    print(f\"   Min: {players_per_play.min()}\")\n",
    "    print(f\"   Max: {players_per_play.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heatmaps",
   "metadata": {},
   "source": [
    "## 9. Field Position Heatmaps üó∫Ô∏è\n",
    "\n",
    "Visualizing player positions on the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'x' in input_df.columns and 'y' in input_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Sample for heatmap\n",
    "    sample = input_df.sample(min(10000, len(input_df)))\n",
    "    \n",
    "    # 1. Overall position heatmap\n",
    "    axes[0, 0].hexbin(sample['x'], sample['y'], gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "    axes[0, 0].set_title('Player Position Heatmap', fontweight='bold', fontsize=14)\n",
    "    axes[0, 0].set_xlabel('X (yards)')\n",
    "    axes[0, 0].set_ylabel('Y (yards)')\n",
    "    axes[0, 0].set_xlim(0, 120)\n",
    "    axes[0, 0].set_ylim(0, 53.3)\n",
    "    \n",
    "    # 2. Speed heatmap\n",
    "    if 's' in input_df.columns:\n",
    "        speed_scatter = axes[0, 1].scatter(sample['x'], sample['y'], c=sample['s'], \n",
    "                                          cmap='viridis', s=1, alpha=0.5)\n",
    "        axes[0, 1].set_title('Speed Distribution on Field', fontweight='bold', fontsize=14)\n",
    "        axes[0, 1].set_xlabel('X (yards)')\n",
    "        axes[0, 1].set_ylabel('Y (yards)')\n",
    "        axes[0, 1].set_xlim(0, 120)\n",
    "        axes[0, 1].set_ylim(0, 53.3)\n",
    "        plt.colorbar(speed_scatter, ax=axes[0, 1], label='Speed (yards/sec)')\n",
    "    \n",
    "    # 3. Ball landing positions\n",
    "    if 'ball_land_x' in input_df.columns and 'ball_land_y' in input_df.columns:\n",
    "        axes[1, 0].hexbin(sample['ball_land_x'], sample['ball_land_y'], \n",
    "                         gridsize=30, cmap='Blues', mincnt=1)\n",
    "        axes[1, 0].set_title('Ball Landing Positions', fontweight='bold', fontsize=14)\n",
    "        axes[1, 0].set_xlabel('X (yards)')\n",
    "        axes[1, 0].set_ylabel('Y (yards)')\n",
    "        axes[1, 0].set_xlim(0, 120)\n",
    "        axes[1, 0].set_ylim(0, 53.3)\n",
    "    \n",
    "    # 4. Field zones\n",
    "    axes[1, 1].scatter(sample['x'], sample['y'], s=1, alpha=0.3, c='blue')\n",
    "    # Add zone lines\n",
    "    axes[1, 1].axvline(20, color='red', linestyle='--', linewidth=2, label='Red Zone')\n",
    "    axes[1, 1].axvline(60, color='green', linestyle='--', linewidth=2, label='Midfield')\n",
    "    axes[1, 1].axhline(26.65, color='orange', linestyle='--', linewidth=2, label='Field Center')\n",
    "    axes[1, 1].set_title('Field Zones', fontweight='bold', fontsize=14)\n",
    "    axes[1, 1].set_xlabel('X (yards)')\n",
    "    axes[1, 1].set_ylabel('Y (yards)')\n",
    "    axes[1, 1].set_xlim(0, 120)\n",
    "    axes[1, 1].set_ylim(0, 53.3)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'field_heatmaps.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Field heatmaps saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insights",
   "metadata": {},
   "source": [
    "## 10. Key Insights üí°\n",
    "\n",
    "Summary of findings from data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insights_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° KEY INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Speed insights\n",
    "if 's' in input_df.columns:\n",
    "    mean_speed = input_df['s'].mean()\n",
    "    max_speed = input_df['s'].max()\n",
    "    insights.append(f\"Average player speed: {mean_speed:.2f} yards/sec\")\n",
    "    insights.append(f\"Maximum observed speed: {max_speed:.2f} yards/sec\")\n",
    "\n",
    "# Field coverage\n",
    "if 'x' in input_df.columns and 'y' in input_df.columns:\n",
    "    x_coverage = (input_df['x'].max() - input_df['x'].min())\n",
    "    y_coverage = (input_df['y'].max() - input_df['y'].min())\n",
    "    insights.append(f\"Field coverage: {x_coverage:.1f} yards (length) √ó {y_coverage:.1f} yards (width)\")\n",
    "\n",
    "# Player diversity\n",
    "if 'player_position' in input_df.columns:\n",
    "    n_positions = input_df['player_position'].nunique()\n",
    "    top_position = input_df['player_position'].mode()[0]\n",
    "    insights.append(f\"Number of unique positions: {n_positions}\")\n",
    "    insights.append(f\"Most common position: {top_position}\")\n",
    "\n",
    "# Missing data\n",
    "missing_pct = 100 * input_df.isnull().sum().sum() / (input_df.shape[0] * input_df.shape[1])\n",
    "insights.append(f\"Overall missing data: {missing_pct:.2f}%\")\n",
    "\n",
    "# Data volume\n",
    "if 'game_id' in input_df.columns and 'play_id' in input_df.columns:\n",
    "    n_games = input_df['game_id'].nunique()\n",
    "    n_plays = input_df['play_id'].nunique()\n",
    "    insights.append(f\"Games in dataset: {n_games}\")\n",
    "    insights.append(f\"Plays in dataset: {n_plays}\")\n",
    "    insights.append(f\"Frames per play (avg): {input_df.groupby('play_id')['frame_id'].nunique().mean():.1f}\")\n",
    "\n",
    "# Print insights\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"\\n{i}. {insight}\")\n",
    "\n",
    "# Save insights\n",
    "with open(OUTPUT_DIR / 'insights.txt', 'w') as f:\n",
    "    f.write(\"KEY INSIGHTS FROM DATA EXPLORATION\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    for i, insight in enumerate(insights, 1):\n",
    "        f.write(f\"{i}. {insight}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Insights saved to insights.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Exploration Complete!\n",
    "\n",
    "### What we learned:\n",
    "- ‚úÖ Data structure and column meanings\n",
    "- ‚úÖ Statistical distributions and patterns\n",
    "- ‚úÖ Correlations between features\n",
    "- ‚úÖ Player position characteristics\n",
    "- ‚úÖ Spatial patterns on the field\n",
    "\n",
    "### Next Steps:\n",
    "1. Use insights for feature engineering (`03_feature_engineering.ipynb`)\n",
    "2. Build and compare models (`04_model_comparison.ipynb`)\n",
    "3. Try sequence modeling (`05_lstm_sequence_modeling.ipynb`)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
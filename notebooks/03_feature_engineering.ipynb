{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è NFL Player Movement - Feature Engineering Deep Dive\n",
    "\n",
    "**Comprehensive Feature Engineering for Player Trajectory Prediction**\n",
    "\n",
    "This notebook explores advanced feature engineering techniques for NFL player movement prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Setup & Configuration](#1-setup)\n",
    "2. [Data Loading](#2-data-loading)\n",
    "3. [Physics Features](#3-physics)\n",
    "4. [Spatial Features](#4-spatial)\n",
    "5. [Temporal Features](#5-temporal)\n",
    "6. [NFL Domain Features](#6-nfl)\n",
    "7. [Feature Importance](#7-importance)\n",
    "8. [Feature Correlation](#8-correlation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nclass Config:\n    \"\"\"Feature engineering configuration\"\"\"\n    \n    # Paths\n    DATA_DIR = Path('../data')\n    OUTPUT_DIR = Path('../outputs/feature_engineering')\n    \n    # Data settings\n    USE_SAMPLE = True\n    SAMPLE_SIZE = 50000\n    MAX_FILES = 2\n    RANDOM_STATE = 42\n\nconfig = Config()\nconfig.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"‚úÖ Configuration loaded\")\nprint(f\"   Data directory: {config.DATA_DIR}\")\nprint(f\"   Output directory: {config.OUTPUT_DIR}\")\nprint(f\"   Sample size: {config.SAMPLE_SIZE if config.USE_SAMPLE else 'All data'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading üìÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_data(data_dir, max_files=None, sample_size=None):\n    \"\"\"\n    Load and merge input/output CSV files\n    \n    Args:\n        data_dir: Directory containing train data\n        max_files: Maximum number of files to load\n        sample_size: Sample size for faster processing\n    \n    Returns:\n        merged_df: Merged dataframe with features and targets\n    \"\"\"\n    # Get file lists\n    train_dir = data_dir / 'raw' / 'train'\n    input_files = sorted(train_dir.glob('input_*.csv'))\n    output_files = sorted(train_dir.glob('output_*.csv'))\n    \n    if max_files:\n        input_files = input_files[:max_files]\n        output_files = output_files[:max_files]\n    \n    print(f\"üìÇ Loading {len(input_files)} files...\")\n    \n    # Load and concatenate\n    input_df = pd.concat([pd.read_csv(f) for f in input_files], ignore_index=True)\n    output_df = pd.concat([pd.read_csv(f) for f in output_files], ignore_index=True)\n    \n    # Sample if requested\n    if sample_size and len(input_df) > sample_size:\n        print(f\"üé≤ Sampling {sample_size:,} rows...\")\n        input_df = input_df.sample(n=sample_size, random_state=42)\n        sampled_keys = input_df[['game_id', 'play_id', 'nfl_id', 'frame_id']]\n        output_df = output_df.merge(sampled_keys, on=['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    \n    # Merge input and output\n    merged_df = input_df.merge(\n        output_df[['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']],\n        on=['game_id', 'play_id', 'nfl_id', 'frame_id'],\n        suffixes=('', '_target')\n    )\n    merged_df = merged_df.rename(columns={'x_target': 'target_x', 'y_target': 'target_y'})\n    \n    print(f\"‚úÖ Data loaded: {merged_df.shape}\")\n    return merged_df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data(\n",
    "    config.DATA_DIR,\n",
    "    max_files=config.MAX_FILES,\n",
    "    sample_size=config.SAMPLE_SIZE if config.USE_SAMPLE else None\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Columns: {len(df.columns)}\")\n",
    "print(f\"üìä Shape: {df.shape}\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Physics Features ‚ö°\n",
    "\n",
    "Create physics-based features from player tracking data:\n",
    "- Velocity components (decomposition)\n",
    "- Acceleration components\n",
    "- Momentum (mass √ó velocity)\n",
    "- Kinetic energy (¬Ω √ó mass √ó velocity¬≤)\n",
    "- Direction differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_physics_features(df):\n",
    "    \"\"\"\n",
    "    Create physics-based features\n",
    "    \n",
    "    Features:\n",
    "    - velocity_x, velocity_y: Velocity vector components\n",
    "    - acceleration_x, acceleration_y: Acceleration components\n",
    "    - momentum: Player momentum (mass √ó speed)\n",
    "    - kinetic_energy: Player kinetic energy (¬Ωmv¬≤)\n",
    "    - dir_diff: Difference between orientation and motion direction\n",
    "    - speed_squared: s¬≤ for energy calculations\n",
    "    \"\"\"\n",
    "    print(\"‚öôÔ∏è  Creating physics features...\\n\")\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 1. Velocity components\n",
    "    if 's' in df_copy.columns and 'dir' in df_copy.columns:\n",
    "        df_copy['velocity_x'] = df_copy['s'] * np.cos(np.radians(df_copy['dir']))\n",
    "        df_copy['velocity_y'] = df_copy['s'] * np.sin(np.radians(df_copy['dir']))\n",
    "        df_copy['velocity_magnitude'] = df_copy['s']  # Alias for clarity\n",
    "        print(\"   ‚úì Velocity components (velocity_x, velocity_y)\")\n",
    "    \n",
    "    # 2. Acceleration components\n",
    "    if 'a' in df_copy.columns and 'dir' in df_copy.columns:\n",
    "        df_copy['acceleration_x'] = df_copy['a'] * np.cos(np.radians(df_copy['dir']))\n",
    "        df_copy['acceleration_y'] = df_copy['a'] * np.sin(np.radians(df_copy['dir']))\n",
    "        print(\"   ‚úì Acceleration components (acceleration_x, acceleration_y)\")\n",
    "    \n",
    "    # 3. Momentum (mass √ó velocity)\n",
    "    if 'player_weight' in df_copy.columns and 's' in df_copy.columns:\n",
    "        df_copy['momentum'] = df_copy['player_weight'] * df_copy['s']\n",
    "        df_copy['momentum_x'] = df_copy['player_weight'] * df_copy['velocity_x']\n",
    "        df_copy['momentum_y'] = df_copy['player_weight'] * df_copy['velocity_y']\n",
    "        print(\"   ‚úì Momentum features (momentum, momentum_x, momentum_y)\")\n",
    "    \n",
    "    # 4. Kinetic energy (0.5 √ó mass √ó velocity¬≤)\n",
    "    if 'player_weight' in df_copy.columns and 's' in df_copy.columns:\n",
    "        df_copy['speed_squared'] = df_copy['s'] ** 2\n",
    "        df_copy['kinetic_energy'] = 0.5 * df_copy['player_weight'] * df_copy['speed_squared']\n",
    "        print(\"   ‚úì Kinetic energy (kinetic_energy, speed_squared)\")\n",
    "    \n",
    "    # 5. Direction difference (orientation vs motion)\n",
    "    if 'o' in df_copy.columns and 'dir' in df_copy.columns:\n",
    "        dir_diff = df_copy['o'] - df_copy['dir']\n",
    "        # Handle wraparound (keep in -180 to 180 range)\n",
    "        dir_diff = (dir_diff + 180) % 360 - 180\n",
    "        df_copy['dir_diff'] = np.abs(dir_diff)\n",
    "        df_copy['is_backpedaling'] = (np.abs(dir_diff) > 90).astype(int)\n",
    "        print(\"   ‚úì Direction features (dir_diff, is_backpedaling)\")\n",
    "    \n",
    "    # 6. Speed categories\n",
    "    if 's' in df_copy.columns:\n",
    "        df_copy['is_sprinting'] = (df_copy['s'] > 6).astype(int)\n",
    "        df_copy['is_jogging'] = ((df_copy['s'] > 2) & (df_copy['s'] <= 6)).astype(int)\n",
    "        df_copy['is_stationary'] = (df_copy['s'] <= 2).astype(int)\n",
    "        print(\"   ‚úì Speed categories (is_sprinting, is_jogging, is_stationary)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Physics features created: {len([c for c in df_copy.columns if c not in df.columns])} new features\")\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply physics features\n",
    "df = create_physics_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize physics features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Velocity components scatter\n",
    "sample = df.sample(min(5000, len(df)))\n",
    "scatter = axes[0, 0].scatter(sample['velocity_x'], sample['velocity_y'], \n",
    "                             c=sample['s'], cmap='viridis', alpha=0.5, s=10)\n",
    "axes[0, 0].set_xlabel('Velocity X (yards/sec)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Velocity Y (yards/sec)', fontsize=12)\n",
    "axes[0, 0].set_title('Velocity Components (colored by speed)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axhline(0, color='red', linestyle='--', alpha=0.3)\n",
    "axes[0, 0].axvline(0, color='red', linestyle='--', alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[0, 0], label='Speed (yards/sec)')\n",
    "\n",
    "# 2. Momentum distribution\n",
    "if 'momentum' in df.columns:\n",
    "    axes[0, 1].hist(df['momentum'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[0, 1].axvline(df['momentum'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 1].axvline(df['momentum'].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[0, 1].set_xlabel('Momentum (lbs¬∑yards/sec)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title('Player Momentum Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "# 3. Kinetic energy distribution\n",
    "if 'kinetic_energy' in df.columns:\n",
    "    axes[1, 0].hist(df['kinetic_energy'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "    axes[1, 0].axvline(df['kinetic_energy'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[1, 0].axvline(df['kinetic_energy'].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[1, 0].set_xlabel('Kinetic Energy (lbs¬∑yards¬≤/sec¬≤)', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 0].set_title('Player Kinetic Energy Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 4. Direction difference\n",
    "if 'dir_diff' in df.columns:\n",
    "    axes[1, 1].hist(df['dir_diff'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='cyan')\n",
    "    axes[1, 1].axvline(90, color='red', linestyle='--', linewidth=2, label='90¬∞ (Backpedaling threshold)')\n",
    "    axes[1, 1].set_xlabel('Direction Difference (degrees)', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 1].set_title('Orientation vs Motion Direction Difference', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'physics_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Physics features visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Features üó∫Ô∏è\n",
    "\n",
    "Create spatial relationship features:\n",
    "- Distance to ball landing spot\n",
    "- Field position features (zones, normalized coordinates)\n",
    "- Sideline proximity\n",
    "- Angle to ball\n",
    "- Red zone indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spatial_features(df):\n",
    "    \"\"\"\n",
    "    Create spatial relationship features\n",
    "    \n",
    "    Features:\n",
    "    - dist_to_ball: Euclidean distance to ball landing\n",
    "    - dx_to_ball, dy_to_ball: Directional distances\n",
    "    - angle_to_ball: Angle from player to ball\n",
    "    - field_position_norm: Normalized field position\n",
    "    - in_red_zone, in_midfield: Field zone indicators\n",
    "    - dist_to_sideline, sideline_norm: Sideline proximity\n",
    "    - dist_to_endzone: Distance to nearest endzone\n",
    "    \"\"\"\n",
    "    print(\"üó∫Ô∏è  Creating spatial features...\\n\")\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 1. Distance to ball landing\n",
    "    if all(col in df_copy.columns for col in ['x', 'y', 'ball_land_x', 'ball_land_y']):\n",
    "        df_copy['dx_to_ball'] = df_copy['ball_land_x'] - df_copy['x']\n",
    "        df_copy['dy_to_ball'] = df_copy['ball_land_y'] - df_copy['y']\n",
    "        df_copy['dist_to_ball'] = np.sqrt(df_copy['dx_to_ball']**2 + df_copy['dy_to_ball']**2)\n",
    "        print(\"   ‚úì Ball distance features (dist_to_ball, dx_to_ball, dy_to_ball)\")\n",
    "        \n",
    "        # Angle to ball\n",
    "        df_copy['angle_to_ball'] = np.degrees(np.arctan2(df_copy['dy_to_ball'], df_copy['dx_to_ball']))\n",
    "        print(\"   ‚úì Angle to ball (angle_to_ball)\")\n",
    "    \n",
    "    # 2. Field position features\n",
    "    if 'x' in df_copy.columns:\n",
    "        df_copy['field_position_norm'] = df_copy['x'] / 120.0\n",
    "        df_copy['in_red_zone'] = (df_copy['x'] <= 20).astype(int)\n",
    "        df_copy['in_midfield'] = ((df_copy['x'] > 40) & (df_copy['x'] < 80)).astype(int)\n",
    "        df_copy['dist_to_endzone'] = np.minimum(df_copy['x'], 120 - df_copy['x'])\n",
    "        print(\"   ‚úì Field position (field_position_norm, in_red_zone, in_midfield, dist_to_endzone)\")\n",
    "    \n",
    "    # 3. Sideline proximity\n",
    "    if 'y' in df_copy.columns:\n",
    "        df_copy['dist_to_sideline'] = np.minimum(df_copy['y'], 53.3 - df_copy['y'])\n",
    "        df_copy['sideline_norm'] = df_copy['dist_to_sideline'] / 26.65\n",
    "        df_copy['y_normalized'] = df_copy['y'] / 53.3\n",
    "        df_copy['near_sideline'] = (df_copy['dist_to_sideline'] < 5).astype(int)\n",
    "        print(\"   ‚úì Sideline features (dist_to_sideline, sideline_norm, near_sideline)\")\n",
    "    \n",
    "    # 4. Field zones (dividing field into regions)\n",
    "    if 'x' in df_copy.columns and 'y' in df_copy.columns:\n",
    "        df_copy['field_zone_x'] = pd.cut(df_copy['x'], bins=5, labels=False)\n",
    "        df_copy['field_zone_y'] = pd.cut(df_copy['y'], bins=3, labels=False)\n",
    "        print(\"   ‚úì Field zones (field_zone_x, field_zone_y)\")\n",
    "    \n",
    "    # 5. Absolute yardline position\n",
    "    if 'absolute_yardline_number' in df_copy.columns:\n",
    "        df_copy['yardline_norm'] = df_copy['absolute_yardline_number'] / 100.0\n",
    "        print(\"   ‚úì Yardline normalized (yardline_norm)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Spatial features created: {len([c for c in df_copy.columns if c not in df.columns])} new features\")\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply spatial features\n",
    "df = create_spatial_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spatial features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Distance to ball distribution\n",
    "if 'dist_to_ball' in df.columns:\n",
    "    axes[0, 0].hist(df['dist_to_ball'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='blue')\n",
    "    axes[0, 0].axvline(df['dist_to_ball'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].axvline(df['dist_to_ball'].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[0, 0].set_xlabel('Distance to Ball Landing (yards)', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title('Distance to Ball Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "# 2. Field zones heatmap\n",
    "if 'x' in df.columns and 'y' in df.columns:\n",
    "    sample = df.sample(min(10000, len(df)))\n",
    "    heatmap, xedges, yedges = np.histogram2d(sample['x'], sample['y'], bins=[30, 15])\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    im = axes[0, 1].imshow(heatmap.T, extent=extent, origin='lower', cmap='YlOrRd', aspect='auto')\n",
    "    axes[0, 1].set_xlabel('X Position (yards)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Y Position (yards)', fontsize=12)\n",
    "    axes[0, 1].set_title('Player Position Density Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, ax=axes[0, 1], label='Density')\n",
    "\n",
    "# 3. Sideline proximity\n",
    "if 'dist_to_sideline' in df.columns:\n",
    "    axes[1, 0].hist(df['dist_to_sideline'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1, 0].axvline(5, color='red', linestyle='--', linewidth=2, label='5 yards (near sideline)')\n",
    "    axes[1, 0].set_xlabel('Distance to Nearest Sideline (yards)', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 0].set_title('Sideline Proximity Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 4. Angle to ball\n",
    "if 'angle_to_ball' in df.columns:\n",
    "    axes[1, 1].hist(df['angle_to_ball'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "    axes[1, 1].set_xlabel('Angle to Ball (degrees)', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 1].set_title('Angle to Ball Landing Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'spatial_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Spatial features visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Features ‚è±Ô∏è\n",
    "\n",
    "### ‚ö†Ô∏è **DATA LEAKAGE WARNING** ‚ö†Ô∏è\n",
    "\n",
    "<div style=\"background-color: #ffcccc; padding: 15px; border-left: 5px solid red; margin: 10px 0;\">\n",
    "<strong>IMPORTANT: Temporal features use information from past AND future frames!</strong>\n",
    "\n",
    "**These features MUST be created AFTER train/test split to avoid data leakage.**\n",
    "\n",
    "Why?\n",
    "- Changes (dx, dy) use information from the next frame\n",
    "- Rolling statistics use information from surrounding frames\n",
    "- If created before splitting, validation data \"leaks\" into training data\n",
    "\n",
    "**Best Practice:**\n",
    "1. Split data first (train/validation)\n",
    "2. Create temporal features separately for each split\n",
    "3. Never use temporal features across split boundaries\n",
    "</div>\n",
    "\n",
    "This section demonstrates temporal feature creation (for educational purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Create temporal features from time-series tracking data\n",
    "    \n",
    "    ‚ö†Ô∏è WARNING: Use ONLY after train/test split to avoid data leakage!\n",
    "    \n",
    "    Features:\n",
    "    - x_change, y_change: Position changes from previous frame\n",
    "    - s_change, a_change: Speed/acceleration changes\n",
    "    - dir_change: Direction change (with wraparound handling)\n",
    "    - acceleration_rate: Rate of acceleration change\n",
    "    \"\"\"\n",
    "    print(\"‚è±Ô∏è  Creating temporal features...\\n\")\n",
    "    print(\"‚ö†Ô∏è  WARNING: These features should only be used AFTER train/test split!\\n\")\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Sort by game, play, player, and frame\n",
    "    if all(col in df_copy.columns for col in ['game_id', 'play_id', 'nfl_id', 'frame_id']):\n",
    "        df_copy = df_copy.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "        \n",
    "        # Group by player within play\n",
    "        group_cols = ['game_id', 'play_id', 'nfl_id']\n",
    "        \n",
    "        # 1. Position changes\n",
    "        for col in ['x', 'y']:\n",
    "            if col in df_copy.columns:\n",
    "                df_copy[f'{col}_change'] = df_copy.groupby(group_cols)[col].diff()\n",
    "        print(\"   ‚úì Position changes (x_change, y_change)\")\n",
    "        \n",
    "        # 2. Speed and acceleration changes\n",
    "        for col in ['s', 'a']:\n",
    "            if col in df_copy.columns:\n",
    "                df_copy[f'{col}_change'] = df_copy.groupby(group_cols)[col].diff()\n",
    "        print(\"   ‚úì Speed/acceleration changes (s_change, a_change)\")\n",
    "        \n",
    "        # 3. Direction change (with wraparound)\n",
    "        if 'dir' in df_copy.columns:\n",
    "            dir_diff = df_copy.groupby(group_cols)['dir'].diff()\n",
    "            # Handle wraparound (-180 to 180)\n",
    "            dir_diff = (dir_diff + 180) % 360 - 180\n",
    "            df_copy['dir_change'] = dir_diff\n",
    "            df_copy['dir_change_abs'] = np.abs(dir_diff)\n",
    "        print(\"   ‚úì Direction changes (dir_change, dir_change_abs)\")\n",
    "        \n",
    "        # 4. Acceleration rate (jerk - derivative of acceleration)\n",
    "        if 'a_change' in df_copy.columns:\n",
    "            df_copy['acceleration_rate'] = df_copy.groupby(group_cols)['a_change'].diff()\n",
    "        print(\"   ‚úì Acceleration rate (acceleration_rate)\")\n",
    "        \n",
    "        # Fill NaN from diff operations\n",
    "        change_cols = [c for c in df_copy.columns if '_change' in c or 'acceleration_rate' in c]\n",
    "        df_copy[change_cols] = df_copy[change_cols].fillna(0)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Temporal features created: {len([c for c in df_copy.columns if c not in df.columns])} new features\")\n",
    "    print(\"‚ö†Ô∏è  Remember: Only use these AFTER train/test split!\")\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate temporal features (for visualization only)\n",
    "# In practice, create these AFTER splitting data\n",
    "df_with_temporal = create_temporal_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Position changes\n",
    "if 'x_change' in df_with_temporal.columns:\n",
    "    axes[0, 0].hist(df_with_temporal['x_change'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='blue')\n",
    "    axes[0, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('X Position Change (yards)', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title('Frame-to-Frame X Position Changes', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Speed changes\n",
    "if 's_change' in df_with_temporal.columns:\n",
    "    axes[0, 1].hist(df_with_temporal['s_change'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Speed Change (yards/sec)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title('Frame-to-Frame Speed Changes', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Direction changes\n",
    "if 'dir_change_abs' in df_with_temporal.columns:\n",
    "    axes[1, 0].hist(df_with_temporal['dir_change_abs'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1, 0].set_xlabel('Absolute Direction Change (degrees)', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 0].set_title('Frame-to-Frame Direction Changes', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Acceleration rate\n",
    "if 'acceleration_rate' in df_with_temporal.columns:\n",
    "    axes[1, 1].hist(df_with_temporal['acceleration_rate'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "    axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Acceleration Rate (yards/sec¬≥)', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 1].set_title('Acceleration Rate (Jerk)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'temporal_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Temporal features visualized\")\n",
    "print(\"‚ö†Ô∏è  Note: In production, create these AFTER splitting data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. NFL Domain Features üèà\n",
    "\n",
    "Create NFL-specific features based on domain knowledge:\n",
    "- Player role indicators (receiver, passer, defender)\n",
    "- Route detection (depth, lateral movement)\n",
    "- Formation indicators\n",
    "- Player physical attributes\n",
    "- Side of ball (offense/defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nfl_features(df):\n",
    "    \"\"\"\n",
    "    Create NFL-specific domain features\n",
    "    \n",
    "    Features:\n",
    "    - Player role indicators (targeted receiver, passer, defender)\n",
    "    - Route features (depth, lateral movement)\n",
    "    - Physical attributes (BMI, age)\n",
    "    - Side indicators (offense/defense)\n",
    "    - Position-based features\n",
    "    \"\"\"\n",
    "    print(\"üèà Creating NFL domain features...\\n\")\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 1. Player role encoding\n",
    "    if 'player_role' in df_copy.columns:\n",
    "        df_copy['is_targeted_receiver'] = (df_copy['player_role'] == 'Targeted Receiver').astype(int)\n",
    "        df_copy['is_passer'] = (df_copy['player_role'] == 'Passer').astype(int)\n",
    "        df_copy['is_defensive'] = (df_copy['player_role'] == 'Defensive Coverage').astype(int)\n",
    "        print(\"   ‚úì Player role indicators (is_targeted_receiver, is_passer, is_defensive)\")\n",
    "    \n",
    "    # 2. Route features\n",
    "    if 'x' in df_copy.columns:\n",
    "        df_copy['route_depth'] = df_copy['x'].abs()\n",
    "    \n",
    "    if 'y' in df_copy.columns:\n",
    "        field_center = 26.65\n",
    "        df_copy['lateral_movement'] = df_copy['y'] - field_center\n",
    "        df_copy['lateral_movement_abs'] = np.abs(df_copy['lateral_movement'])\n",
    "        print(\"   ‚úì Route features (route_depth, lateral_movement, lateral_movement_abs)\")\n",
    "    \n",
    "    # 3. Physical attributes\n",
    "    if 'player_height' in df_copy.columns and 'player_weight' in df_copy.columns:\n",
    "        # BMI calculation (weight in lbs, height in inches)\n",
    "        df_copy['player_bmi'] = (df_copy['player_weight'] / (df_copy['player_height'] ** 2)) * 703\n",
    "        print(\"   ‚úì Physical attributes (player_bmi)\")\n",
    "    \n",
    "    # 4. Player age (if birth date available)\n",
    "    if 'player_birth_date' in df_copy.columns:\n",
    "        try:\n",
    "            df_copy['player_birth_date'] = pd.to_datetime(df_copy['player_birth_date'], errors='coerce')\n",
    "            reference_date = pd.Timestamp('2023-01-01')  # Approximate season date\n",
    "            df_copy['player_age'] = (reference_date - df_copy['player_birth_date']).dt.days / 365.25\n",
    "            print(\"   ‚úì Player age (player_age)\")\n",
    "        except:\n",
    "            print(\"   ‚ö†Ô∏è  Could not calculate player age\")\n",
    "    \n",
    "    # 5. Side of ball\n",
    "    if 'player_side' in df_copy.columns:\n",
    "        df_copy['is_offense'] = (df_copy['player_side'] == 'offense').astype(int)\n",
    "        df_copy['is_defense'] = (df_copy['player_side'] == 'defense').astype(int)\n",
    "        print(\"   ‚úì Side indicators (is_offense, is_defense)\")\n",
    "    \n",
    "    # 6. Position group encoding\n",
    "    if 'player_position' in df_copy.columns:\n",
    "        # Group positions\n",
    "        receivers = ['WR', 'TE']\n",
    "        backs = ['RB', 'FB']\n",
    "        linemen = ['OL', 'DL', 'OT', 'OG', 'C', 'DE', 'DT', 'NT']\n",
    "        linebackers = ['LB', 'ILB', 'MLB', 'OLB']\n",
    "        defensive_backs = ['CB', 'S', 'SS', 'FS', 'DB']\n",
    "        \n",
    "        df_copy['is_receiver'] = df_copy['player_position'].isin(receivers).astype(int)\n",
    "        df_copy['is_back'] = df_copy['player_position'].isin(backs).astype(int)\n",
    "        df_copy['is_lineman'] = df_copy['player_position'].isin(linemen).astype(int)\n",
    "        df_copy['is_linebacker'] = df_copy['player_position'].isin(linebackers).astype(int)\n",
    "        df_copy['is_defensive_back'] = df_copy['player_position'].isin(defensive_backs).astype(int)\n",
    "        df_copy['is_qb'] = (df_copy['player_position'] == 'QB').astype(int)\n",
    "        print(\"   ‚úì Position groups (is_receiver, is_back, is_lineman, is_linebacker, is_defensive_back, is_qb)\")\n",
    "    \n",
    "    # 7. Play direction adjustment\n",
    "    if 'play_direction' in df_copy.columns:\n",
    "        df_copy['play_direction_left'] = (df_copy['play_direction'] == 'left').astype(int)\n",
    "        df_copy['play_direction_right'] = (df_copy['play_direction'] == 'right').astype(int)\n",
    "        print(\"   ‚úì Play direction (play_direction_left, play_direction_right)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ NFL features created: {len([c for c in df_copy.columns if c not in df.columns])} new features\")\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NFL features (continue from df, not df_with_temporal to avoid temporal leakage)\n",
    "df = create_nfl_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize NFL features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Player role distribution\n",
    "if all(col in df.columns for col in ['is_targeted_receiver', 'is_passer', 'is_defensive']):\n",
    "    role_counts = [\n",
    "        df['is_targeted_receiver'].sum(),\n",
    "        df['is_passer'].sum(),\n",
    "        df['is_defensive'].sum(),\n",
    "        len(df) - df['is_targeted_receiver'].sum() - df['is_passer'].sum() - df['is_defensive'].sum()\n",
    "    ]\n",
    "    role_labels = ['Targeted Receiver', 'Passer', 'Defensive Coverage', 'Other']\n",
    "    axes[0, 0].bar(role_labels, role_counts, color=['green', 'blue', 'red', 'gray'], alpha=0.7)\n",
    "    axes[0, 0].set_ylabel('Count', fontsize=12)\n",
    "    axes[0, 0].set_title('Player Role Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Route depth by role\n",
    "if 'route_depth' in df.columns and 'is_targeted_receiver' in df.columns:\n",
    "    receivers = df[df['is_targeted_receiver'] == 1]['route_depth'].dropna()\n",
    "    others = df[df['is_targeted_receiver'] == 0]['route_depth'].dropna()\n",
    "    axes[0, 1].hist([receivers, others], bins=30, label=['Targeted Receiver', 'Others'], alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Route Depth (yards)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title('Route Depth by Player Role', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "# 3. BMI distribution\n",
    "if 'player_bmi' in df.columns:\n",
    "    axes[1, 0].hist(df['player_bmi'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "    axes[1, 0].axvline(df['player_bmi'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[1, 0].set_xlabel('Player BMI', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1, 0].set_title('Player BMI Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 4. Speed by position group\n",
    "if 's' in df.columns and any(col in df.columns for col in ['is_receiver', 'is_back', 'is_lineman']):\n",
    "    position_speeds = []\n",
    "    position_labels = []\n",
    "    \n",
    "    if 'is_receiver' in df.columns:\n",
    "        position_speeds.append(df[df['is_receiver'] == 1]['s'].dropna())\n",
    "        position_labels.append('Receiver')\n",
    "    if 'is_back' in df.columns:\n",
    "        position_speeds.append(df[df['is_back'] == 1]['s'].dropna())\n",
    "        position_labels.append('Back')\n",
    "    if 'is_lineman' in df.columns:\n",
    "        position_speeds.append(df[df['is_lineman'] == 1]['s'].dropna())\n",
    "        position_labels.append('Lineman')\n",
    "    \n",
    "    if position_speeds:\n",
    "        axes[1, 1].boxplot(position_speeds, labels=position_labels)\n",
    "        axes[1, 1].set_ylabel('Speed (yards/sec)', fontsize=12)\n",
    "        axes[1, 1].set_title('Speed Distribution by Position Group', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'nfl_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ NFL features visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis üìä\n",
    "\n",
    "Analyze which features are most important for predicting player movement using a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature importance analysis\n",
    "print(\"üìä Preparing data for feature importance analysis...\\n\")\n",
    "\n",
    "# Exclude ID columns and non-numeric features\n",
    "exclude_cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'target_x', 'target_y',\n",
    "                'player_name', 'player_position', 'player_role', 'player_side',\n",
    "                'play_direction', 'player_birth_date', 'player_to_predict']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Prepare features and targets\n",
    "X = df[feature_cols].fillna(0)\n",
    "y_x = df['target_x'].fillna(df['target_x'].median())\n",
    "y_y = df['target_y'].fillna(df['target_y'].median())\n",
    "\n",
    "print(f\"‚úÖ Data prepared\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "print(f\"   Samples: {X.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for feature importance\n",
    "print(\"\\nüå≥ Training Random Forest for feature importance...\\n\")\n",
    "\n",
    "# Use smaller sample for faster training\n",
    "sample_size = min(20000, len(X))\n",
    "sample_idx = np.random.choice(len(X), sample_size, replace=False)\n",
    "\n",
    "X_sample = X.iloc[sample_idx]\n",
    "y_sample = y_x.iloc[sample_idx]\n",
    "\n",
    "# Train model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_sample, y_sample)\n",
    "\n",
    "print(\"‚úÖ Random Forest trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"\\nüèÜ Top 20 Most Important Features:\\n\")\n",
    "display(feature_importances.head(20))\n",
    "\n",
    "# Save to CSV\n",
    "feature_importances.to_csv(config.OUTPUT_DIR / 'feature_importances.csv', index=False)\n",
    "print(f\"\\n‚úÖ Feature importances saved to: {config.OUTPUT_DIR / 'feature_importances.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importances\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top 20 features bar chart\n",
    "top_n = 20\n",
    "top_features = feature_importances.head(top_n)\n",
    "\n",
    "axes[0].barh(range(len(top_features)), top_features['importance'], color='steelblue', alpha=0.8)\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=12)\n",
    "axes[0].set_title(f'Top {top_n} Most Important Features', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Cumulative importance\n",
    "cumsum = feature_importances['importance'].cumsum()\n",
    "axes[1].plot(range(1, len(cumsum) + 1), cumsum, linewidth=2, color='darkgreen')\n",
    "axes[1].axhline(0.9, color='red', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].axhline(0.95, color='orange', linestyle='--', linewidth=2, label='95% threshold')\n",
    "axes[1].set_xlabel('Number of Features', fontsize=12)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=12)\n",
    "axes[1].set_title('Cumulative Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'feature_importances.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate features needed for 90% and 95% importance\n",
    "n_90 = (cumsum >= 0.90).argmax() + 1\n",
    "n_95 = (cumsum >= 0.95).argmax() + 1\n",
    "\n",
    "print(f\"\\nüìà Feature Selection Insights:\")\n",
    "print(f\"   Features for 90% importance: {n_90}\")\n",
    "print(f\"   Features for 95% importance: {n_95}\")\n",
    "print(f\"   Total features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Correlation Analysis üîó\n",
    "\n",
    "Analyze correlations between features and targets, and identify multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with targets\n",
    "print(\"üîó Calculating feature correlations with targets...\\n\")\n",
    "\n",
    "correlations_x = []\n",
    "correlations_y = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    # Correlation with target_x\n",
    "    valid_idx_x = (~X[col].isna()) & (~y_x.isna())\n",
    "    if valid_idx_x.sum() > 100:\n",
    "        corr_x, _ = pearsonr(X.loc[valid_idx_x, col], y_x[valid_idx_x])\n",
    "        correlations_x.append({'feature': col, 'correlation': corr_x})\n",
    "    \n",
    "    # Correlation with target_y\n",
    "    valid_idx_y = (~X[col].isna()) & (~y_y.isna())\n",
    "    if valid_idx_y.sum() > 100:\n",
    "        corr_y, _ = pearsonr(X.loc[valid_idx_y, col], y_y[valid_idx_y])\n",
    "        correlations_y.append({'feature': col, 'correlation': corr_y})\n",
    "\n",
    "correlations_x_df = pd.DataFrame(correlations_x).sort_values('correlation', key=abs, ascending=False)\n",
    "correlations_y_df = pd.DataFrame(correlations_y).sort_values('correlation', key=abs, ascending=False)\n",
    "\n",
    "print(\"‚úÖ Correlations calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top correlations\n",
    "print(\"\\nüéØ Top 15 Features Correlated with Target X:\\n\")\n",
    "display(correlations_x_df.head(15))\n",
    "\n",
    "print(\"\\nüéØ Top 15 Features Correlated with Target Y:\\n\")\n",
    "display(correlations_y_df.head(15))\n",
    "\n",
    "# Save correlations\n",
    "correlations_x_df.to_csv(config.OUTPUT_DIR / 'correlations_target_x.csv', index=False)\n",
    "correlations_y_df.to_csv(config.OUTPUT_DIR / 'correlations_target_y.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Correlations saved to: {config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top 15 correlations with X\n",
    "top_15_x = correlations_x_df.head(15)\n",
    "colors_x = ['green' if c > 0 else 'red' for c in top_15_x['correlation']]\n",
    "\n",
    "axes[0].barh(range(len(top_15_x)), top_15_x['correlation'], color=colors_x, alpha=0.7)\n",
    "axes[0].set_yticks(range(len(top_15_x)))\n",
    "axes[0].set_yticklabels(top_15_x['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].axvline(0, color='black', linewidth=1)\n",
    "axes[0].set_xlabel('Correlation with Target X', fontsize=12)\n",
    "axes[0].set_title('Top 15 Features Correlated with Target X', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Top 15 correlations with Y\n",
    "top_15_y = correlations_y_df.head(15)\n",
    "colors_y = ['green' if c > 0 else 'red' for c in top_15_y['correlation']]\n",
    "\n",
    "axes[1].barh(range(len(top_15_y)), top_15_y['correlation'], color=colors_y, alpha=0.7)\n",
    "axes[1].set_yticks(range(len(top_15_y)))\n",
    "axes[1].set_yticklabels(top_15_y['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].axvline(0, color='black', linewidth=1)\n",
    "axes[1].set_xlabel('Correlation with Target Y', fontsize=12)\n",
    "axes[1].set_title('Top 15 Features Correlated with Target Y', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'feature_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Correlation visualizations saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-to-feature correlation (multicollinearity detection)\n",
    "print(\"\\nüîó Analyzing feature-to-feature correlations...\\n\")\n",
    "\n",
    "# Use top 30 most important features for correlation matrix\n",
    "top_30_features = feature_importances.head(30)['feature'].tolist()\n",
    "X_top = X[top_30_features]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = X_top.corr()\n",
    "\n",
    "# Visualize correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "ax.set_title('Feature Correlation Heatmap (Top 30 Features)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'feature_correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append({\n",
    "                'feature_1': corr_matrix.columns[i],\n",
    "                'feature_2': corr_matrix.columns[j],\n",
    "                'correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('correlation', key=abs, ascending=False)\n",
    "    print(\"\\n‚ö†Ô∏è  Highly Correlated Feature Pairs (|r| > 0.8):\")\n",
    "    print(\"    Consider removing one from each pair to reduce multicollinearity\\n\")\n",
    "    display(high_corr_df)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No highly correlated feature pairs found (|r| > 0.8)\")\n",
    "\n",
    "print(\"\\n‚úÖ Multicollinearity analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Feature Engineering Complete!\n",
    "\n",
    "### Summary:\n",
    "\n",
    "‚úÖ **Physics Features**: Velocity, acceleration, momentum, kinetic energy, direction differences  \n",
    "‚úÖ **Spatial Features**: Distance to ball, field position, sideline proximity, angles  \n",
    "‚úÖ **Temporal Features**: Position/speed/direction changes (‚ö†Ô∏è use after split!)  \n",
    "‚úÖ **NFL Features**: Player roles, routes, formations, physical attributes  \n",
    "‚úÖ **Feature Importance**: Identified most predictive features  \n",
    "‚úÖ **Correlation Analysis**: Analyzed relationships with targets and multicollinearity  \n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Most Important Features**: Current position (x, y), speed, distance to ball, player role\n",
    "2. **Feature Selection**: 90% importance can be achieved with top N features\n",
    "3. **Multicollinearity**: Some features highly correlated (consider removing)\n",
    "4. **Temporal Features**: Powerful but must be created after train/test split\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Use these features in `04_model_comparison.ipynb`\n",
    "2. Experiment with feature selection (drop low-importance features)\n",
    "3. Create interaction features\n",
    "4. Try polynomial features for non-linear relationships\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
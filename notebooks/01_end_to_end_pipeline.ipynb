{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 🏈 NFL Player Movement Prediction - Complete Pipeline\n",
    "\n",
    "**End-to-End Machine Learning Workflow**\n",
    "\n",
    "This notebook demonstrates the complete ML pipeline for predicting NFL player movements during pass plays.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Table of Contents\n",
    "\n",
    "1. [Setup & Configuration](#1-setup)\n",
    "2. [Data Loading](#2-data-loading)\n",
    "3. [Data Exploration](#3-exploration)\n",
    "4. [Data Preparation](#4-preparation)\n",
    "5. [Feature Engineering](#5-features)\n",
    "6. [Train/Val Split](#6-split)\n",
    "7. [Model Training](#7-training)\n",
    "8. [Model Evaluation](#8-evaluation)\n",
    "9. [Predictions](#9-predictions)\n",
    "10. [Save Results](#10-save)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration 🔧\n",
    "\n",
    "Import libraries and set up configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Try to import XGBoost (optional)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGBOOST = True\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "    print(\"⚠️  XGBoost not installed. Install with: pip install xgboost\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")\n",
    "print(f\"   XGBoost available: {HAS_XGBOOST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    \"\"\"Pipeline configuration\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = Path('../data')\n",
    "    OUTPUT_DIR = Path('../outputs/end_to_end_pipeline')\n",
    "    \n",
    "    # Data settings\n",
    "    USE_SAMPLE = True  # Set to False for full data\n",
    "    SAMPLE_SIZE = 100000  # Number of rows to sample\n",
    "    MAX_FILES = 2  # Number of weekly files to load\n",
    "    \n",
    "    # Train/Val split\n",
    "    VAL_SIZE = 0.2  # 20% validation set\n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    # Feature engineering flags\n",
    "    USE_PHYSICS_FEATURES = True\n",
    "    USE_SPATIAL_FEATURES = True\n",
    "    USE_TEMPORAL_FEATURES = True  # ⚠️ Only after split!\n",
    "    USE_NFL_FEATURES = True\n",
    "    \n",
    "    # Models to train\n",
    "    MODELS = ['ridge', 'random_forest']\n",
    "    if HAS_XGBOOST:\n",
    "        MODELS.append('xgboost')\n",
    "\n",
    "# Create config instance\n",
    "config = Config()\n",
    "\n",
    "# Create output directory\n",
    "config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✅ Configuration loaded\")\n",
    "print(f\"   Data directory: {config.DATA_DIR}\")\n",
    "print(f\"   Output directory: {config.OUTPUT_DIR}\")\n",
    "print(f\"   Sample size: {config.SAMPLE_SIZE if config.USE_SAMPLE else 'All data'}\")\n",
    "print(f\"   Models: {config.MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Data Loading 📂\n",
    "\n",
    "Load and merge input/output data files from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "def load_data(data_dir, max_files=None, sample_size=None):\n    \"\"\"\n    Load and merge input/output CSV files\n    \n    Args:\n        data_dir: Directory containing train data\n        max_files: Maximum number of files to load (None = all)\n        sample_size: Sample size for faster testing (None = all)\n    \n    Returns:\n        input_df, output_df: Input and output dataframes\n    \"\"\"\n    train_dir = data_dir / 'train'\n    \n    # Get file lists\n    input_files = sorted(train_dir.glob('input_*.csv'))\n    output_files = sorted(train_dir.glob('output_*.csv'))\n    \n    if max_files:\n        input_files = input_files[:max_files]\n        output_files = output_files[:max_files]\n    \n    print(f\"📂 Loading {len(input_files)} input files and {len(output_files)} output files...\")\n    \n    # Load input files\n    input_dfs = []\n    for file in input_files:\n        df = pd.read_csv(file)\n        input_dfs.append(df)\n        print(f\"   ✓ {file.name}: {len(df):,} rows\")\n    \n    input_df = pd.concat(input_dfs, ignore_index=True)\n    \n    # Load output files\n    output_dfs = []\n    for file in output_files:\n        df = pd.read_csv(file)\n        output_dfs.append(df)\n    \n    output_df = pd.concat(output_dfs, ignore_index=True)\n    \n    # Sample if requested\n    if sample_size and len(input_df) > sample_size:\n        print(f\"\\n🎲 Sampling {sample_size:,} rows from {len(input_df):,}...\")\n        input_df = input_df.sample(n=sample_size, random_state=42)\n        # Filter output to match sampled input using proper keys\n        sampled_keys = input_df[['game_id', 'play_id', 'nfl_id', 'frame_id']]\n        output_df = output_df.merge(sampled_keys, on=['game_id', 'play_id', 'nfl_id', 'frame_id'])\n        output_df = output_df.reset_index(drop=True)\n    \n    print(f\"\\n✅ Data loaded successfully\")\n    print(f\"   Input shape: {input_df.shape}\")\n    print(f\"   Output shape: {output_df.shape}\")\n    \n    return input_df, output_df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "input_df, output_df = load_data(\n",
    "    config.DATA_DIR,\n",
    "    max_files=config.MAX_FILES,\n",
    "    sample_size=config.SAMPLE_SIZE if config.USE_SAMPLE else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Data Exploration 🔍\n",
    "\n",
    "Quick exploration of the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Input Data Sample:\")\n",
    "display(input_df.head())\n",
    "\n",
    "print(\"\\n📊 Output Data Sample:\")\n",
    "display(output_df.head())\n",
    "\n",
    "print(\"\\n📋 Input Columns:\")\n",
    "print(input_df.columns.tolist())\n",
    "\n",
    "print(\"\\n❓ Missing Values:\")\n",
    "missing = input_df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "if len(missing) > 0:\n",
    "    for col, count in missing.head(10).items():\n",
    "        pct = 100 * count / len(input_df)\n",
    "        print(f\"   {col}: {count:,} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"   ✓ No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Speed distribution\n",
    "if 's' in input_df.columns:\n",
    "    axes[0, 0].hist(input_df['s'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_title('Speed Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Speed (yards/sec)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Acceleration distribution\n",
    "if 'a' in input_df.columns:\n",
    "    axes[0, 1].hist(input_df['a'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[0, 1].set_title('Acceleration Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Acceleration (yards/sec²)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Field positions\n",
    "if 'x' in input_df.columns and 'y' in input_df.columns:\n",
    "    sample = input_df.sample(min(5000, len(input_df)))\n",
    "    axes[1, 0].scatter(sample['x'], sample['y'], alpha=0.3, s=1, c='blue')\n",
    "    axes[1, 0].set_title('Player Positions on Field', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('X (yards)')\n",
    "    axes[1, 0].set_ylabel('Y (yards)')\n",
    "    axes[1, 0].set_xlim(0, 120)\n",
    "    axes[1, 0].set_ylim(0, 53.3)\n",
    "\n",
    "# Target distribution\n",
    "if 'x' in output_df.columns:\n",
    "    axes[1, 1].hist(output_df['x'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1, 1].set_title('Target X Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Future X Position (yards)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'data_exploration.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Data Preparation 🧹\n",
    "\n",
    "Clean, merge, and prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "def prepare_data(input_df, output_df):\n    \"\"\"\n    Prepare data for modeling:\n    1. Merge input and output\n    2. Handle missing values\n    3. Fix data types\n    4. Remove outliers\n    \n    Returns:\n        merged_df: Prepared dataframe\n    \"\"\"\n    print(\"=\"*70)\n    print(\"DATA PREPARATION\")\n    print(\"=\"*70)\n    \n    # 1. Merge input and output\n    print(\"\\n1️⃣ Merging input and output data...\")\n    merged_df = input_df.merge(\n        output_df[['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']],\n        on=['game_id', 'play_id', 'nfl_id', 'frame_id'],\n        suffixes=('', '_target')\n    )\n    merged_df = merged_df.rename(columns={'x_target': 'target_x', 'y_target': 'target_y'})\n    print(f\"   ✓ Merged shape: {merged_df.shape}\")\n    \n    # 2. Handle missing values\n    print(\"\\n2️⃣ Handling missing values...\")\n    initial_nulls = merged_df.isnull().sum().sum()\n    \n    # Fill numeric columns with median\n    numeric_cols = merged_df.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        if merged_df[col].isnull().any():\n            median_val = merged_df[col].median()\n            merged_df[col].fillna(median_val, inplace=True)\n    \n    # Fill categorical columns with mode\n    cat_cols = merged_df.select_dtypes(include=['object']).columns\n    for col in cat_cols:\n        if merged_df[col].isnull().any():\n            mode_val = merged_df[col].mode()[0] if len(merged_df[col].mode()) > 0 else 'Unknown'\n            merged_df[col].fillna(mode_val, inplace=True)\n    \n    final_nulls = merged_df.isnull().sum().sum()\n    print(f\"   ✓ Nulls: {initial_nulls} → {final_nulls}\")\n    \n    # 3. Remove outliers (using IQR method)\n    print(\"\\n3️⃣ Removing outliers...\")\n    initial_rows = len(merged_df)\n    \n    for col in ['s', 'a', 'target_x', 'target_y']:\n        if col in merged_df.columns:\n            Q1 = merged_df[col].quantile(0.01)\n            Q3 = merged_df[col].quantile(0.99)\n            merged_df = merged_df[(merged_df[col] >= Q1) & (merged_df[col] <= Q3)]\n    \n    final_rows = len(merged_df)\n    removed = initial_rows - final_rows\n    print(f\"   ✓ Removed {removed:,} outliers ({100*removed/initial_rows:.2f}%)\")\n    \n    print(f\"\\n✅ Data preparation complete\")\n    print(f\"   Final shape: {merged_df.shape}\")\n    print(f\"   Memory: {merged_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n    \n    return merged_df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "prepared_df = prepare_data(input_df, output_df)\n",
    "\n",
    "print(\"\\n📋 Prepared data sample:\")\n",
    "display(prepared_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering ⚙️\n",
    "\n",
    "Create physics-based, spatial, and NFL-specific features\n",
    "\n",
    "**Note:** Temporal features are created AFTER train/test split to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_physics_features(df):\n",
    "    \"\"\"\n",
    "    Create physics-based features:\n",
    "    - Velocity components (v_x, v_y)\n",
    "    - Acceleration components\n",
    "    - Momentum\n",
    "    - Kinetic energy\n",
    "    \"\"\"\n",
    "    print(\"⚙️  Creating physics features...\")\n",
    "    \n",
    "    # Velocity components\n",
    "    if 's' in df.columns and 'dir' in df.columns:\n",
    "        df['velocity_x'] = df['s'] * np.cos(np.radians(df['dir']))\n",
    "        df['velocity_y'] = df['s'] * np.sin(np.radians(df['dir']))\n",
    "    \n",
    "    # Acceleration components\n",
    "    if 'a' in df.columns and 'dir' in df.columns:\n",
    "        df['acceleration_x'] = df['a'] * np.cos(np.radians(df['dir']))\n",
    "        df['acceleration_y'] = df['a'] * np.sin(np.radians(df['dir']))\n",
    "    \n",
    "    # Momentum (mass × velocity)\n",
    "    if 'player_weight' in df.columns and 's' in df.columns:\n",
    "        df['momentum'] = df['player_weight'] * df['s']\n",
    "    \n",
    "    # Kinetic energy (0.5 × mass × velocity²)\n",
    "    if 'player_weight' in df.columns and 's' in df.columns:\n",
    "        df['kinetic_energy'] = 0.5 * df['player_weight'] * (df['s'] ** 2)\n",
    "    \n",
    "    print(f\"   ✓ Added physics features\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_spatial_features(df):\n",
    "    \"\"\"\n",
    "    Create spatial features:\n",
    "    - Distance to ball landing\n",
    "    - Field position features\n",
    "    - Sideline proximity\n",
    "    \"\"\"\n",
    "    print(\"⚙️  Creating spatial features...\")\n",
    "    \n",
    "    # Distance to ball landing\n",
    "    if all(col in df.columns for col in ['x', 'y', 'ball_land_x', 'ball_land_y']):\n",
    "        df['dist_to_ball'] = np.sqrt(\n",
    "            (df['x'] - df['ball_land_x'])**2 + \n",
    "            (df['y'] - df['ball_land_y'])**2\n",
    "        )\n",
    "        df['dx_to_ball'] = df['ball_land_x'] - df['x']\n",
    "        df['dy_to_ball'] = df['ball_land_y'] - df['y']\n",
    "    \n",
    "    # Field position features\n",
    "    if 'x' in df.columns:\n",
    "        df['field_position_norm'] = df['x'] / 120.0\n",
    "        df['in_red_zone'] = (df['x'] <= 20).astype(int)\n",
    "    \n",
    "    # Sideline distance\n",
    "    if 'y' in df.columns:\n",
    "        df['dist_to_sideline'] = np.minimum(df['y'], 53.3 - df['y'])\n",
    "        df['sideline_norm'] = df['dist_to_sideline'] / 26.65\n",
    "    \n",
    "    print(f\"   ✓ Added spatial features\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_nfl_features(df):\n",
    "    \"\"\"\n",
    "    Create NFL-specific features:\n",
    "    - Player roles\n",
    "    - Formation indicators\n",
    "    - Route detection\n",
    "    \"\"\"\n",
    "    print(\"⚙️  Creating NFL domain features...\")\n",
    "    \n",
    "    # Encode player roles\n",
    "    if 'player_role' in df.columns:\n",
    "        df['is_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "        df['is_passer'] = (df['player_role'] == 'Passer').astype(int)\n",
    "        df['is_defensive'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    \n",
    "    # Route depth\n",
    "    if 'x' in df.columns:\n",
    "        df['route_depth'] = df['x'].abs()\n",
    "    \n",
    "    # Lateral movement\n",
    "    if 'y' in df.columns:\n",
    "        df['lateral_movement'] = df['y'] - 26.65  # Distance from field center\n",
    "    \n",
    "    print(f\"   ✓ Added NFL domain features\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering (before split - no temporal features!)\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE ENGINEERING (Pre-Split)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if config.USE_PHYSICS_FEATURES:\n",
    "    prepared_df = create_physics_features(prepared_df)\n",
    "\n",
    "if config.USE_SPATIAL_FEATURES:\n",
    "    prepared_df = create_spatial_features(prepared_df)\n",
    "\n",
    "if config.USE_NFL_FEATURES:\n",
    "    prepared_df = create_nfl_features(prepared_df)\n",
    "\n",
    "print(f\"\\n✅ Feature engineering complete (pre-split)\")\n",
    "print(f\"   Total features: {len(prepared_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Train/Validation Split 🔀\n",
    "\n",
    "Split data into training and validation sets using temporal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(df, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train and validation sets\n",
    "    Uses temporal split if game_id available, otherwise random\n",
    "    \n",
    "    Returns:\n",
    "        train_df, val_df\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"TRAIN/VALIDATION SPLIT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if 'game_id' in df.columns:\n",
    "        # Temporal split by game\n",
    "        print(\"\\n📅 Using temporal split by game...\")\n",
    "        unique_games = df['game_id'].unique()\n",
    "        np.random.seed(random_state)\n",
    "        np.random.shuffle(unique_games)\n",
    "        \n",
    "        split_idx = int(len(unique_games) * (1 - val_size))\n",
    "        train_games = unique_games[:split_idx]\n",
    "        val_games = unique_games[split_idx:]\n",
    "        \n",
    "        train_df = df[df['game_id'].isin(train_games)].reset_index(drop=True)\n",
    "        val_df = df[df['game_id'].isin(val_games)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   Train games: {len(train_games)}\")\n",
    "        print(f\"   Val games: {len(val_games)}\")\n",
    "    else:\n",
    "        # Random split\n",
    "        print(\"\\n🎲 Using random split...\")\n",
    "        val_size_rows = int(len(df) * val_size)\n",
    "        val_df = df.sample(n=val_size_rows, random_state=random_state)\n",
    "        train_df = df[~df.index.isin(val_df.index)].reset_index(drop=True)\n",
    "        val_df = val_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n✅ Split complete\")\n",
    "    print(f\"   Train: {len(train_df):,} rows ({100*len(train_df)/len(df):.1f}%)\")\n",
    "    print(f\"   Val: {len(val_df):,} rows ({100*len(val_df)/len(df):.1f}%)\")\n",
    "    \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df = train_val_split(prepared_df, val_size=config.VAL_SIZE, random_state=config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add temporal features (AFTER split to avoid leakage)\n",
    "def create_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Create temporal features (changes over time)\n",
    "    ⚠️ WARNING: Only use AFTER train/test split to avoid data leakage!\n",
    "    \"\"\"\n",
    "    print(\"⚠️  Creating temporal features (post-split)...\")\n",
    "    \n",
    "    # Sort for temporal calculations\n",
    "    if all(col in df.columns for col in ['game_id', 'play_id', 'nfl_id', 'frame_id']):\n",
    "        df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id']).reset_index(drop=True)\n",
    "        \n",
    "        # Position changes\n",
    "        for col in ['x', 'y']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_change'] = df.groupby(['game_id', 'play_id', 'nfl_id'])[col].diff()\n",
    "        \n",
    "        # Speed and acceleration changes\n",
    "        for col in ['s', 'a']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_change'] = df.groupby(['game_id', 'play_id', 'nfl_id'])[col].diff()\n",
    "        \n",
    "        # Fill NaN from diff with 0\n",
    "        change_cols = [c for c in df.columns if '_change' in c]\n",
    "        df[change_cols] = df[change_cols].fillna(0)\n",
    "    \n",
    "    print(f\"   ✓ Added temporal features\")\n",
    "    return df\n",
    "\n",
    "if config.USE_TEMPORAL_FEATURES:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEMPORAL FEATURE ENGINEERING (Post-Split)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    train_df = create_temporal_features(train_df)\n",
    "    val_df = create_temporal_features(val_df)\n",
    "    print(f\"\\n✅ Temporal features added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare X and y for modeling\ndef prepare_model_data(df):\n    \"\"\"\n    Prepare features (X) and targets (y) for modeling\n    \"\"\"\n    # Identify feature columns (exclude IDs and targets)\n    exclude_cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', \n                    'target_x', 'target_y', 'player_name', 'player_position']\n    \n    feature_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]\n    \n    X = df[feature_cols].fillna(0)\n    y_x = df['target_x'].fillna(df['target_x'].median())\n    y_y = df['target_y'].fillna(df['target_y'].median())\n    \n    return X, y_x, y_y, feature_cols\n\n# Prepare training data\nX_train, y_train_x, y_train_y, feature_names = prepare_model_data(train_df)\n\n# Prepare validation data\nX_val, y_val_x, y_val_y, _ = prepare_model_data(val_df)\n\nprint(f\"✅ Model data prepared\")\nprint(f\"   X_train: {X_train.shape}\")\nprint(f\"   X_val: {X_val.shape}\")\nprint(f\"   Features: {len(feature_names)}\")\nprint(f\"\\n📋 Sample features: {feature_names[:10]}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Model Training 🤖\n",
    "\n",
    "Train multiple models to predict future player positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, model_type='ridge'):\n",
    "    \"\"\"\n",
    "    Train a model and evaluate on validation set\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_val, y_val: Validation data\n",
    "        model_type: Type of model ('ridge', 'random_forest', 'xgboost')\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        metrics: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n🤖 Training {model_type.upper()} model...\")\n",
    "    \n",
    "    # Select model\n",
    "    if model_type == 'ridge':\n",
    "        model = Ridge(alpha=1.0, random_state=42)\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            min_samples_split=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_type == 'xgboost' and HAS_XGBOOST:\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        'val_rmse': np.sqrt(mean_squared_error(y_val, y_pred_val)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_pred_train),\n",
    "        'val_mae': mean_absolute_error(y_val, y_pred_val),\n",
    "        'train_r2': r2_score(y_train, y_pred_train),\n",
    "        'val_r2': r2_score(y_val, y_pred_val)\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✓ Train RMSE: {metrics['train_rmse']:.4f}\")\n",
    "    print(f\"   ✓ Val RMSE: {metrics['val_rmse']:.4f}\")\n",
    "    print(f\"   ✓ Val R²: {metrics['val_r2']:.4f}\")\n",
    "    \n",
    "    return model, metrics, y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for X coordinate\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING MODELS - X COORDINATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models_x = {}\n",
    "predictions_x = {}\n",
    "metrics_x = {}\n",
    "\n",
    "for model_name in config.MODELS:\n",
    "    model, metrics, y_pred = train_model(X_train, y_train_x, X_val, y_val_x, model_type=model_name)\n",
    "    models_x[model_name] = model\n",
    "    metrics_x[model_name] = metrics\n",
    "    predictions_x[model_name] = y_pred\n",
    "\n",
    "print(\"\\n✅ X coordinate models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for Y coordinate\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING MODELS - Y COORDINATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models_y = {}\n",
    "predictions_y = {}\n",
    "metrics_y = {}\n",
    "\n",
    "for model_name in config.MODELS:\n",
    "    model, metrics, y_pred = train_model(X_train, y_train_y, X_val, y_val_y, model_type=model_name)\n",
    "    models_y[model_name] = model\n",
    "    metrics_y[model_name] = metrics\n",
    "    predictions_y[model_name] = y_pred\n",
    "\n",
    "print(\"\\n✅ Y coordinate models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation 📊\n",
    "\n",
    "Compare model performance and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for model_name in config.MODELS:\n",
    "    comparison_data.append({\n",
    "        'Model': model_name.upper(),\n",
    "        'X_RMSE': metrics_x[model_name]['val_rmse'],\n",
    "        'Y_RMSE': metrics_y[model_name]['val_rmse'],\n",
    "        'X_MAE': metrics_x[model_name]['val_mae'],\n",
    "        'Y_MAE': metrics_y[model_name]['val_mae'],\n",
    "        'X_R2': metrics_x[model_name]['val_r2'],\n",
    "        'Y_R2': metrics_y[model_name]['val_r2']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n📊 Model Performance Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "best_x_model = comparison_df.loc[comparison_df['X_RMSE'].idxmin(), 'Model']\n",
    "best_y_model = comparison_df.loc[comparison_df['Y_RMSE'].idxmin(), 'Model']\n",
    "\n",
    "print(f\"\\n🏆 Best model for X: {best_x_model}\")\n",
    "print(f\"🏆 Best model for Y: {best_y_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# RMSE comparison\n",
    "x_rmse = [metrics_x[m]['val_rmse'] for m in config.MODELS]\n",
    "y_rmse = [metrics_y[m]['val_rmse'] for m in config.MODELS]\n",
    "model_labels = [m.upper() for m in config.MODELS]\n",
    "\n",
    "x_pos = np.arange(len(model_labels))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, x_rmse, width, label='X Coordinate', alpha=0.8)\n",
    "axes[0].bar(x_pos + width/2, y_rmse, width, label='Y Coordinate', alpha=0.8)\n",
    "axes[0].set_xlabel('Model', fontsize=12)\n",
    "axes[0].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('Model RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(model_labels)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# R² comparison\n",
    "x_r2 = [metrics_x[m]['val_r2'] for m in config.MODELS]\n",
    "y_r2 = [metrics_y[m]['val_r2'] for m in config.MODELS]\n",
    "\n",
    "axes[1].bar(x_pos - width/2, x_r2, width, label='X Coordinate', alpha=0.8, color='orange')\n",
    "axes[1].bar(x_pos + width/2, y_r2, width, label='Y Coordinate', alpha=0.8, color='green')\n",
    "axes[1].set_xlabel('Model', fontsize=12)\n",
    "axes[1].set_ylabel('R² Score', fontsize=12)\n",
    "axes[1].set_title('Model R² Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(model_labels)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Model comparison visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 9. Predictions & Visualization 🎯\n",
    "\n",
    "Generate predictions and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best models\n",
    "best_model_x = models_x[best_x_model.lower()]\n",
    "best_model_y = models_y[best_y_model.lower()]\n",
    "best_pred_x = predictions_x[best_x_model.lower()]\n",
    "best_pred_y = predictions_y[best_y_model.lower()]\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# X predictions vs actual\n",
    "axes[0, 0].scatter(y_val_x, best_pred_x, alpha=0.3, s=1)\n",
    "axes[0, 0].plot([y_val_x.min(), y_val_x.max()], [y_val_x.min(), y_val_x.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual X', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted X', fontsize=12)\n",
    "axes[0, 0].set_title(f'X Predictions ({best_x_model})', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Y predictions vs actual\n",
    "axes[0, 1].scatter(y_val_y, best_pred_y, alpha=0.3, s=1, color='orange')\n",
    "axes[0, 1].plot([y_val_y.min(), y_val_y.max()], [y_val_y.min(), y_val_y.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('Actual Y', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Predicted Y', fontsize=12)\n",
    "axes[0, 1].set_title(f'Y Predictions ({best_y_model})', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# X residuals\n",
    "residuals_x = y_val_x - best_pred_x\n",
    "axes[1, 0].hist(residuals_x, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Residual (Actual - Predicted)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 0].set_title('X Residual Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Y residuals\n",
    "residuals_y = y_val_y - best_pred_y\n",
    "axes[1, 1].hist(residuals_y, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Residual (Actual - Predicted)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 1].set_title('Y Residual Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.OUTPUT_DIR / 'predictions_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Prediction visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## 10. Save Results 💾\n",
    "\n",
    "Save trained models and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "print(\"💾 Saving models and results...\")\n",
    "\n",
    "# Save best models\n",
    "with open(config.OUTPUT_DIR / 'best_model_x.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_x, f)\n",
    "\n",
    "with open(config.OUTPUT_DIR / 'best_model_y.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_y, f)\n",
    "\n",
    "# Save feature names\n",
    "with open(config.OUTPUT_DIR / 'feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)\n",
    "\n",
    "# Save metrics\n",
    "comparison_df.to_csv(config.OUTPUT_DIR / 'model_comparison.csv', index=False)\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'best_model_x': best_x_model,\n",
    "    'best_model_y': best_y_model,\n",
    "    'x_rmse': float(comparison_df.loc[comparison_df['Model'] == best_x_model, 'X_RMSE'].values[0]),\n",
    "    'y_rmse': float(comparison_df.loc[comparison_df['Model'] == best_y_model, 'Y_RMSE'].values[0]),\n",
    "    'num_features': len(feature_names),\n",
    "    'train_size': len(train_df),\n",
    "    'val_size': len(val_df)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(config.OUTPUT_DIR / 'summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Results saved to: {config.OUTPUT_DIR}\")\n",
    "print(\"\\n📋 Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 Pipeline Complete!\n",
    "\n",
    "### Summary:\n",
    "- ✅ Data loaded and prepared\n",
    "- ✅ Features engineered (physics, spatial, temporal, NFL-specific)\n",
    "- ✅ Models trained and evaluated\n",
    "- ✅ Results saved and visualized\n",
    "\n",
    "### Next Steps:\n",
    "1. Explore `02_data_exploration.ipynb` for deeper data analysis\n",
    "2. Try `03_feature_engineering.ipynb` for advanced feature creation\n",
    "3. Compare more models in `04_model_comparison.ipynb`\n",
    "4. Experiment with LSTM in `05_lstm_sequence_modeling.ipynb`\n",
    "5. Generate final predictions in `06_prediction_and_evaluation.ipynb`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}